{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd96b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for Windows\n",
    "\n",
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa47e972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for Mac\n",
    "\n",
    "pip install -r requirements_mac.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd01819",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "work_dir = os.path.abspath(os.path.join('..'))\n",
    "if work_dir not in sys.path:\n",
    "    sys.path.append(work_dir+\"/src/\")\n",
    "    \n",
    "print(work_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae0a0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "\n",
    "import glob\n",
    "import itertools\n",
    "import re\n",
    "import umap\n",
    "import hdbscan\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from lstm_train import train\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from visualization import hdbscan_figure, umap_figure, LSTM_hdbscan_figure, LSTM_umap_figure\n",
    "\n",
    "from IPython import display\n",
    "from IPython.display import Image, Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33cd660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting keypoints\n",
    "\n",
    "keypoint_names = ['mouth', 'head', 'dorsal_front', 'dorsal_center', 'dorsal_back', 'caudal_fin']\n",
    "\n",
    "key_characters = [f'distance_{keypoint_names[1]}-{keypoint_names[1]}',\n",
    "                  f'alignment_{keypoint_names[1]}-{keypoint_names[0]}',\n",
    "                  f'alignment_{keypoint_names[4]}-{keypoint_names[3]}',\n",
    "                  f'angles_{keypoint_names[1]}-{keypoint_names[0]} to {keypoint_names[1]}',\n",
    "                  f'angles_{keypoint_names[4]}-{keypoint_names[3]} to {keypoint_names[1]}',\n",
    "                  f'angles_{keypoint_names[1]}-{keypoint_names[0]} to {keypoint_names[4]}',\n",
    "                  f'angles_{keypoint_names[4]}-{keypoint_names[3]} to {keypoint_names[4]}']\n",
    "\n",
    "key_characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2409849c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## key_character explanation\n",
    "\n",
    "display.display(Image(work_dir + '/data/key_characters.png', embed=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d236e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sampled frames with key characters\n",
    "## key characters were already calculated from raw tracking data\n",
    "sampled_df = pd.read_csv(work_dir + '/data/sampled_umap_cluster.csv')\n",
    "\n",
    "## extract train_data with UMAP-HDBSCAN clustering ids (umap_neighbor == 15)\n",
    "\n",
    "train_data = sampled_df[key_characters].to_numpy()\n",
    "train_label = sampled_df['cluster_un15'].to_numpy()\n",
    "\n",
    "## standardize the train data\n",
    "\n",
    "scaler = StandardScaler().fit(train_data)\n",
    "train_data = scaler.transform(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7634b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create umap model\n",
    "\n",
    "umap_train = umap.UMAP(n_neighbors=15, random_state=0).fit(train_data)\n",
    "train_data = umap_train.embedding_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18edb7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize umap embedding of key characters of frames with HDBSCAN clustering resutls\n",
    "## HDBSCAN clustering is only for visualization, not used for further steps\n",
    "\n",
    "## UMAP embedding without clustering results\n",
    "umap_figure(train_data)\n",
    "\n",
    "## UMAP embedding with HDBSCAN clustering results\n",
    "hdbscan_figure(train_data, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74488566",
   "metadata": {},
   "outputs": [],
   "source": [
    "## examples of pose clusters\n",
    "\n",
    "display.display(Image(work_dir + '/data/example_pose_cluster.png', embed=True))\n",
    "\n",
    "## red arrow represents head of each fish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c5dedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time stamps for pre-classified behaviors\n",
    "## example_motion_class.csv includes time stamps of lateral display and bite behavior\n",
    "\n",
    "time_stamp_df = pd.read_csv(work_dir + '/data/example_motion_class.csv')\n",
    "\n",
    "trial_path = os.path.join(work_dir+'/data/multi_*.csv')\n",
    "trial_ls = glob.glob(os.path.normpath(trial_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e161fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_stamp_df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65aba137",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_df_sample = pd.read_csv(trial_ls[0])[:10]\n",
    "\n",
    "trial_df_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47233ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create input data for training LSTM autoencoder\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "max_seq_len = 0\n",
    "raw_behav_seq = []\n",
    "true_labels = []\n",
    "for trial in trial_ls:\n",
    "    ## import feature and time_stamp dataframes\n",
    "    trial_df = pd.read_csv(trial)\n",
    "    trial_name = re.split(r'\\\\|/', trial)[-1][:-12]\n",
    "    print(f\"import data from {trial_name}\")\n",
    "    \n",
    "    file_time_stamp = time_stamp_df[time_stamp_df['file']==trial_name]\n",
    "    \n",
    "    trial_df_labeled = pd.DataFrame()\n",
    "    for index, row in file_time_stamp.iterrows():\n",
    "        \n",
    "        ## calculate start & end frames of each behavior\n",
    "        ### raw videos were divided into three files due to the camera setting\n",
    "        ### each file has 63660 frames\n",
    "        part = int(row['part'])-1 \n",
    "        bout_start = row['start'] + (part*63660) \n",
    "        bout_end = row['end'] + (part*63660) \n",
    "        \n",
    "        ## save true labels\n",
    "        bout_class = row['class']\n",
    "        true_labels.append(bout_class)\n",
    "        \n",
    "        ## transform key characters of each behaviors into umap embedding\n",
    "        bout_df = trial_df[(trial_df['time_stamp'] >= bout_start) & (trial_df['time_stamp'] <= bout_end)]\n",
    "        bout_feature = bout_df[key_characters].to_numpy()\n",
    "        bout_feature = scaler.transform(bout_feature)\n",
    "        bout_umap = umap_train.transform(bout_feature)\n",
    "        \n",
    "        ## upadate max_seq_len for zero-padding\n",
    "        if bout_umap.shape[0] > max_seq_len:\n",
    "            max_seq_len = bout_umap.shape[0]\n",
    "        \n",
    "        raw_behav_seq.append(bout_umap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63863b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "## zero-padding to max_seq_len\n",
    "\n",
    "input_seq = []\n",
    "for indiv_seq in raw_behav_seq:\n",
    "    indiv_seq = np.array(indiv_seq)\n",
    "    pad_width_0 = (max_seq_len-indiv_seq.shape[0])//2\n",
    "    pad_width_1 = (max_seq_len-indiv_seq.shape[0]) - pad_width_0\n",
    "    indiv_seq_pad = np.pad(indiv_seq, ((pad_width_0, pad_width_1),(0, 0)))\n",
    "    input_seq.append(indiv_seq_pad)\n",
    "    \n",
    "input_seq = np.array(input_seq)\n",
    "\n",
    "input_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f3be31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train LSTM autoencoder\n",
    "# Mac with M1 chips need special setting for using tensorflow libraries\n",
    "# For this course, we provide pretrained lstm models for Mac users.\n",
    "# please choose the right cell for your machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cc6b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For Windows\n",
    "\n",
    "## setting parameters\n",
    "LEARNING_RATE = 0.0005\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 100\n",
    "\n",
    "## train LSTM autoencoder\n",
    "Autoencoder, Encoder, Decoder = train(input_seq, LEARNING_RATE, BATCH_SIZE, EPOCHS)\n",
    "\n",
    "## get latent_representation of input sequences\n",
    "latent_representation = Encoder.predict(input_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f34cfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "## for Mac users with M1 chips\n",
    "from tensorflow import keras\n",
    "\n",
    "## load pretrained lstm encoder\n",
    "encoder_path = work_dir + f\"/data/lstm_model/lstm_encoder\"\n",
    "Encoder = keras.models.load_model(encoder_path, compile=False)\n",
    "\n",
    "## get latent_representation of input sequences\n",
    "latent_representation = Encoder.predict(input_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bb22e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HDBSCAN clustering of latent representations\n",
    "\n",
    "cluster_labels_df = pd.DataFrame()\n",
    "umap_neighbor = [10, 15, 20]\n",
    "for neighbor in umap_neighbor:\n",
    "    print(f\"Results with umap_neighbor = {neighbor}\")\n",
    "    ## UMAP with latent representation\n",
    "    reducer = umap.UMAP(random_state=0, n_neighbors=neighbor).fit(latent_representation)\n",
    "    second_embedding = reducer.transform(latent_representation)\n",
    "    ### visualize umap embedding of LSTM latent representation\n",
    "    LSTM_umap_figure(second_embedding)\n",
    "    \n",
    "    ## HDBSCAN clustering\n",
    "    clusterer = hdbscan.HDBSCAN(min_cluster_size=3, min_samples=1)\n",
    "    clusterer.fit(second_embedding)\n",
    "    cluster_labels = clusterer.labels_\n",
    "    ## append cluster_labels\n",
    "    cluster_labels_df[f\"cluster_un{neighbor}\"] = cluster_labels\n",
    "    \n",
    "    ### visualize HDBSCAN clustering\n",
    "    LSTM_hdbscan_figure(second_embedding, cluster_labels, true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1fbdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create datafrane with predicted labels\n",
    "\n",
    "fin_df = pd.concat([time_stamp_df, cluster_labels_df], axis=1)\n",
    "\n",
    "fin_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43721dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the clustering with different umap_neighbor parameters\n",
    "\n",
    "from sklearn.metrics import adjusted_rand_score, adjusted_mutual_info_score\n",
    "\n",
    "## For more information about umap_neighbor, read the doc below. \n",
    "## https://umap-learn.readthedocs.io/en/latest/parameters.html\n",
    "## For more information about metrics below, read the doc below. \n",
    "## https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58023c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_label = fin_df[\"class\"].to_numpy()\n",
    "for neighbor in umap_neighbor:\n",
    "    print(f\"umap_neighbor: {neighbor}\")\n",
    "    pred_label = fin_df[f\"cluster_un{neighbor}\"]\n",
    "    rand_score = adjusted_rand_score(true_label, pred_label)\n",
    "    mutual_info = adjusted_mutual_info_score(true_label, pred_label)\n",
    "    print(f\"adjusted_rand_score for umap_neighbor: {rand_score}\")\n",
    "    print(f\"adjusted_mutual_info for umap_neighbor: {mutual_info}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d150b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load video clips for each cluster\n",
    "\n",
    "video_loc = os.path.join(work_dir+'/data/videos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13681ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "## put the best umap_neighbor below.\n",
    "best_umap_neighbor = 20\n",
    "\n",
    "predicted_groups = fin_df.groupby(f\"cluster_un{best_umap_neighbor}\")\n",
    "\n",
    "clip_dict = {}\n",
    "for pred_label, group in predicted_groups:\n",
    "    \n",
    "    clip_list = group[\"clip_no\"].tolist()\n",
    "    \n",
    "    clip_loc_list = []\n",
    "    for clip in clip_list:\n",
    "        clip_name = \"clip_\" + str(clip)\n",
    "        clip_loc = os.path.normpath(video_loc + f\"/{clip_name}.mp4\")\n",
    "        clip_loc_list.append(clip_loc)\n",
    "        \n",
    "    clip_dict[pred_label] = clip_loc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b46235",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in range(len(clip_dict)):\n",
    "    print(f\"videos for predicted group {key}\")\n",
    "    clip_list = clip_dict[key]\n",
    "    Video(clip_list[0], embed=True)\n",
    "    [display.display(Video(clip_id, embed=True)) for clip_id in clip_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a88911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discussion\n",
    "\n",
    "## 1. What are the major differences in annotations between manual classification and automated classification?\n",
    "## 2. What are the drawbacks of manual and automated behavior classification?\n",
    "## 3. Could we improve the automated behavior classification? If so, how?\n",
    "## 4. What do you prefer between manual and automated behavior classification? and why?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
