{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd96b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd01819",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path+\"\\\\src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472d181c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting working directory\n",
    "\n",
    "work_dir = 'D:\\Lab\\Jordan lab\\outreach\\QMBE_2023\\materials\\VTK_2023_behavior_classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae0a0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "\n",
    "import glob\n",
    "import itertools\n",
    "import umap\n",
    "import hdbscan\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from lstm_train import train\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from visualization import hdbscan_figure, umap_figure, LSTM_hdbscan_figure, LSTM_umap_figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33cd660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting keypoints\n",
    "\n",
    "keypoint_names = ['mouth', 'head', 'dorsal_front', 'dorsal_center', 'dorsal_back', 'caudal_fin']\n",
    "\n",
    "key_characters = [f'distance_{keypoint_names[1]}-{keypoint_names[1]}',\n",
    "                  f'alignment_{keypoint_names[1]}-{keypoint_names[0]}',\n",
    "                  f'alignment_{keypoint_names[4]}-{keypoint_names[3]}',\n",
    "                  f'angles_{keypoint_names[1]}-{keypoint_names[0]} to {keypoint_names[1]}',\n",
    "                  f'angles_{keypoint_names[4]}-{keypoint_names[3]} to {keypoint_names[1]}',\n",
    "                  f'angles_{keypoint_names[1]}-{keypoint_names[0]} to {keypoint_names[4]}',\n",
    "                  f'angles_{keypoint_names[4]}-{keypoint_names[3]} to {keypoint_names[4]}']\n",
    "\n",
    "key_characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d236e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sampled frames with key characters\n",
    "## key characters were already calculated from raw tracking data\n",
    "sampled_df = pd.read_csv(work_dir + '/data/sampled_umap_cluster.csv')\n",
    "\n",
    "## extract train_data with UMAP-HDBSCAN clustering ids (umap_neighbor == 15)\n",
    "\n",
    "train_data = sampled_df[key_characters].to_numpy()\n",
    "train_label = sampled_df['cluster_un15'].to_numpy()\n",
    "\n",
    "## standardize the train data\n",
    "\n",
    "scaler = StandardScaler().fit(train_data)\n",
    "train_data = scaler.transform(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7634b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create umap model\n",
    "\n",
    "umap_train = umap.UMAP(n_neighbors=15, random_state=0).fit(train_data)\n",
    "train_data = umap_train.embedding_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18edb7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize umap embedding of key characters of frames with HDBSCAN clustering resutls\n",
    "## HDBSCAN clustering is only for visualization, not used for further steps\n",
    "\n",
    "## UMAP embedding without clustering results\n",
    "umap_figure(train_data)\n",
    "\n",
    "## UMAP embedding with HDBSCAN clustering results\n",
    "hdbscan_figure(train_data, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74488566",
   "metadata": {},
   "outputs": [],
   "source": [
    "## examples of pose clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c5dedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time stamps for pre-classified behaviors\n",
    "## example_motion_class.csv includes time stamps of lateral display and bite behavior\n",
    "\n",
    "time_stamp_df = pd.read_csv(work_dir + '/data/example_motion_class.csv')\n",
    "\n",
    "trial_path = os.path.join(work_dir+'/data/multi_*.csv')\n",
    "trial_ls = glob.glob(os.path.normpath(trial_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e161fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_stamp_df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65aba137",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_df_sample = pd.read_csv(trial_ls[0])[:10]\n",
    "\n",
    "trial_df_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47233ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create input data for training LSTM autoencoder\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "max_seq_len = 0\n",
    "raw_behav_seq = []\n",
    "true_labels = []\n",
    "for trial in trial_ls:\n",
    "    ## import feature and time_stamp dataframes\n",
    "    trial_df = pd.read_csv(trial)\n",
    "    trial_name = trial.split('\\\\')[-1][:-12]\n",
    "    print(trial_name)\n",
    "    \n",
    "    file_time_stamp = time_stamp_df[time_stamp_df['file']==trial_name]\n",
    "    \n",
    "    trial_df_labeled = pd.DataFrame()\n",
    "    for index, row in file_time_stamp.iterrows():\n",
    "        \n",
    "        ## calculate start & end frames of each behavior\n",
    "        ### raw videos were divided into three files due to the camera setting\n",
    "        ### each file has 63660 frames\n",
    "        part = int(row['part'])-1 \n",
    "        bout_start = row['start'] + (part*63660) \n",
    "        bout_end = row['end'] + (part*63660) \n",
    "        \n",
    "        ## save true labels\n",
    "        bout_class = row['class']\n",
    "        true_labels.append(bout_class)\n",
    "        \n",
    "        ## transform key characters of each behaviors into umap embedding\n",
    "        bout_df = trial_df[(trial_df['time_stamp'] >= bout_start) & (trial_df['time_stamp'] <= bout_end)]\n",
    "        bout_feature = bout_df[key_characters].to_numpy()\n",
    "        bout_feature = scaler.transform(bout_feature)\n",
    "        bout_umap = umap_train.transform(bout_feature)\n",
    "        \n",
    "        ## upadate max_seq_len for zero-padding\n",
    "        if bout_umap.shape[0] > max_seq_len:\n",
    "            max_seq_len = bout_umap.shape[0]\n",
    "        \n",
    "        raw_behav_seq.append(bout_umap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63863b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "## zero-padding to max_seq_len\n",
    "\n",
    "input_seq = []\n",
    "for indiv_seq in raw_behav_seq:\n",
    "    indiv_seq = np.array(indiv_seq)\n",
    "    pad_width_0 = (max_seq_len-indiv_seq.shape[0])//2\n",
    "    pad_width_1 = (max_seq_len-indiv_seq.shape[0]) - pad_width_0\n",
    "    indiv_seq_pad = np.pad(indiv_seq, ((pad_width_0, pad_width_1),(0, 0)))\n",
    "    input_seq.append(indiv_seq_pad)\n",
    "    \n",
    "input_seq = np.array(input_seq)\n",
    "\n",
    "input_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f3be31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train LSTM autoencoder\n",
    "## setting parameters\n",
    "\n",
    "LEARNING_RATE = 0.0005\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cc6b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## train LSTM autoencoder\n",
    "Autoencoder, Encoder, Decoder = train(input_seq, LEARNING_RATE, BATCH_SIZE, EPOCHS)\n",
    "\n",
    "## get latent_representation of input sequences\n",
    "latent_representation = Encoder.predict(input_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bb22e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HDBSCAN clustering of latent representations\n",
    "\n",
    "umap_neighbor = [5, 10]\n",
    "for neighbor in umap_neighbor:\n",
    "    print(f\"Results with umap_neighbor = {neighbor}\")\n",
    "    ## UMAP with latent representation\n",
    "    reducer = umap.UMAP(random_state=0, n_neighbors=neighbor).fit(latent_representation)\n",
    "    second_embedding = reducer.transform(latent_representation)\n",
    "    ### visualize umap embedding of LSTM latent representation\n",
    "    LSTM_umap_figure(second_embedding)\n",
    "    \n",
    "    ## HDBSCAN clustering\n",
    "    clusterer = hdbscan.HDBSCAN(min_cluster_size=5, min_samples=1)\n",
    "    clusterer.fit(second_embedding)\n",
    "    cluster_labels = clusterer.labels_\n",
    "    ### visualize HDBSCAN clustering\n",
    "    LSTM_hdbscan_figure(second_embedding, cluster_labels, true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a88911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The results can be improved by \n",
    "# adding more key characters, changing hyperparamters for UMAP, HDBSCAN, or LSTM autoencoder, etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
